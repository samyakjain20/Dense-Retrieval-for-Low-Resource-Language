{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijgHcV70hkhx",
        "outputId": "8a0d2182-cf45-42cb-d10e-5be42e3b8f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15\n",
            "Mounted at /content/drive\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "\n",
        "!pip install tqdm\n",
        "!pip install datasets\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from datasets import Dataset as ds\n",
        "import random\n",
        "import json\n",
        "\n",
        "import os  # when loading file paths\n",
        "import pandas as pd  # for lookup in annotation file\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence  # pad batch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_44dEmeLiI2C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_path = r\"/content/drive/MyDrive/IRE/project/train_chaii_hi_1.json\"\n",
        "# train_file_path = r\"/content/drive/MyDrive/IRE/project/train.json\"\n",
        "# test_file_path = r\"/content/drive/MyDrive/IRE/project/test.json\"\n",
        "\n",
        "file_path = r\"/content/drive/MyDrive/IRE/train_chaii_hi_1.json\"\n",
        "train_file_path = r\"/content/drive/MyDrive/IRE/train.json\"\n",
        "test_file_path = r\"/content/drive/MyDrive/IRE/test.json\""
      ],
      "metadata": {
        "id": "ttW7wioCTaPh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file):\n",
        "\n",
        "  # Specify the path to your JSON file\n",
        "  json_file_path = file\n",
        "  # Initialize an empty dictionary\n",
        "  data = {}\n",
        "\n",
        "  # Load the JSON data into the dictionary\n",
        "  try:\n",
        "      with open(json_file_path, \"r\") as json_file:\n",
        "          data = json.load(json_file)\n",
        "      print(\"JSON file loaded successfully into a dictionary.\")\n",
        "  except FileNotFoundError:\n",
        "      print(f\"Error: JSON file '{json_file_path}' not found.\")\n",
        "  except json.JSONDecodeError as e:\n",
        "      print(f\"Error decoding JSON: {e}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "\n",
        "  return data\n",
        "\n",
        "train_dict = load_data(train_file_path)\n",
        "test_dict = load_data(test_file_path)\n",
        "print(\"len(train_dict): \", len(train_dict))\n",
        "print(\"len(test_dict): \", len(test_dict))\n",
        "\n",
        "chai_dataset = {\n",
        "  \"train\": {\"question\": [], \"positivie_context\": [], \"negative_context\": []},\n",
        "  \"test\": {\"question\": [], \"positivie_context\": [], \"negative_context\": []},\n",
        "}\n",
        "\n",
        "def get_data(split_type, dict_type, chai_dataset, k):\n",
        "\n",
        "  question_list = []\n",
        "  positive_contest_list = []\n",
        "  negative_contest_list = []\n",
        "  random_seed = 42\n",
        "  random.seed(random_seed)\n",
        "  for i in dict_type:\n",
        "    question_list.append(i['question'])\n",
        "    positive_contest_list.append(i[\"positive_ctxs\"][0]['text'])\n",
        "\n",
        "  for i in range(len(positive_contest_list)):\n",
        "    list1 =[]\n",
        "    for j in range(len(positive_contest_list)):\n",
        "      if(i!=j):\n",
        "        list1.append(positive_contest_list[j])\n",
        "    list1 = random.choices(list1, k=k)\n",
        "    negative_contest_list.append(list1[:])\n",
        "\n",
        "  for i in range(len(question_list)):\n",
        "    chai_dataset[split_type][\"question\"] = question_list\n",
        "    chai_dataset[split_type][\"positivie_context\"] = positive_contest_list\n",
        "    chai_dataset[split_type][\"negative_context\"] = negative_contest_list\n",
        "\n",
        "#build train\n",
        "get_data(\"train\", train_dict, chai_dataset, 10)\n",
        "\n",
        "#build test\n",
        "get_data(\"test\", test_dict, chai_dataset, 10)\n",
        "\n",
        "class chaiDataset(Dataset):\n",
        "  def __init__(self, dataset_object, split_type):\n",
        "    #convert list to pandas datafraame\n",
        "    #create new df\n",
        "    # split_type = 'train'\n",
        "\n",
        "    self.df = pd.DataFrame({'question':dataset_object[split_type]['question'],'positivie_context':dataset_object[split_type]['positivie_context'],'negative_context':dataset_object[split_type]['negative_context']})\n",
        "    # print (\"df:\",self.df)\n",
        "\n",
        "    # Get question columns\n",
        "    self.question = self.df[\"question\"]\n",
        "    # Get positive_context columns\n",
        "    self.positivie_context = self.df[\"positivie_context\"]\n",
        "    # Get the negative_context columns\n",
        "    self.negative_context = self.df[\"negative_context\"]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    question = self.question[index]\n",
        "    positive_context = self.positivie_context[index]\n",
        "    negative_context = self.negative_context[index]\n",
        "\n",
        "    return question, positive_context\n",
        "\n",
        "def get_loader(\n",
        "    dataset_object,\n",
        "    split_type,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "):\n",
        "  dataset = chaiDataset(chai_dataset, split_type)\n",
        "\n",
        "  loader = DataLoader(\n",
        "      dataset=dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "  )\n",
        "\n",
        "  return loader, dataset"
      ],
      "metadata": {
        "id": "MMbf4inPZUFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161b8fa1-b985-453c-ccbe-4a662529b1a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON file loaded successfully into a dictionary.\n",
            "JSON file loaded successfully into a dictionary.\n",
            "len(train_dict):  596\n",
            "len(test_dict):  149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_object = chai_dataset[\"test\"]\n",
        "train_dataset_object = chai_dataset[\"train\"]\n",
        "test_split_type = \"test\"\n",
        "train_split_type = \"train\"\n",
        "batch_size = 8\n",
        "test_dataloader, test_dataset = get_loader(test_dataset_object, test_split_type, batch_size)\n",
        "train_dataloader, train_dataset = get_loader(train_dataset_object, train_split_type, batch_size)"
      ],
      "metadata": {
        "id": "9cxcQbnuZ0gP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "44B0FrVPgx8C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(Encoder, self).__init__()\n",
        "        # cfg_name = \"bert-base-uncased\"\n",
        "        # self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "        cfg = AutoConfig.from_pretrained(model_name)\n",
        "        # self.BertModel= AutoModel.from_pretrained(model_name, config=cfg) # , project_dim=projection_dim, **kwargs\n",
        "        self.BertModel = BertModel.from_pretrained(model_name)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # inputs = tokenizer(x, return_tensors='pt')\n",
        "        # print(\"x = \", x)\n",
        "        # input_ids = self.tokenizer.encode(x, add_special_tokens=True, return_tensors='pt')\n",
        "        # print(\"tokenized x shape = \", input_ids.shape)\n",
        "        # input_ids = x.unsqueeze(0)\n",
        "        # print(\"tokenized x = \", input_ids)\n",
        "        tokenized_batch = self.tokenizer(x, padding=True, truncation=True, add_special_tokens=True, return_tensors='pt')\n",
        "\n",
        "        input_ids = tokenized_batch['input_ids']\n",
        "        # print(\"input_ids shape  \", input_ids.shape)\n",
        "        attention_mask = tokenized_batch['attention_mask']\n",
        "        token_type_ids = tokenized_batch['token_type_ids']\n",
        "        # print(\"outputs shape = \", outputs.shape)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "\n",
        "        outputs = self.BertModel(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "        # print(\"cls shape = \", cls_embeddings.shape)\n",
        "        # cls_embeddings = cls_embeddings.reshape(cls_embeddings.size()[1])\n",
        "        # print(\"output shape= \", outputs.shape)\n",
        "        # print(\"outputs = \", outputs)\n",
        "        # out  = outputs[0]\n",
        "        # print(\"first output shape= \", cls_embeddings.shape)\n",
        "        # print(\"first output = \", cls_embeddings)\n",
        "        return cls_embeddings"
      ],
      "metadata": {
        "id": "KuVy3vFLiI_d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiEncoder(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(BiEncoder, self).__init__()\n",
        "        self.model_name = model_name\n",
        "        self.Q_Encoder = Encoder(model_name)\n",
        "        self.P_Encoder = Encoder(model_name)\n",
        "\n",
        "    def forward(self, question, PositiveDoc):\n",
        "        q_emb = self.Q_Encoder(question)\n",
        "        p_emb = self.P_Encoder(PositiveDoc)\n",
        "\n",
        "        # neg_embs = []\n",
        "        # for NegativeDoc in NegativeDocs:\n",
        "        #     n_emb = self.P_Encoder(NegativeDoc)\n",
        "        #     neg_embs.append(n_emb)\n",
        "\n",
        "        return  q_emb, p_emb"
      ],
      "metadata": {
        "id": "orELS0YyDYxF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def CalculateSim(a, b):\n",
        "#     a = a.numpy()\n",
        "#     b = b.numpy()\n",
        "#     return np.dot(a, b)\n",
        "\n",
        "\n",
        "# def RetrieveSimilarityScores(q_emb, p_emb, n_embs):\n",
        "#     Similarity_Scores = []\n",
        "\n",
        "#     Similarity_Scores.append(CalculateSim(q_emb, p_emb))\n",
        "#     for n_emb in n_embs:\n",
        "#         Similarity_Scores.append(CalculateSim(q_emb, p_emb))\n",
        "\n",
        "#     return np.array(Similarity_Scores)"
      ],
      "metadata": {
        "id": "lsRiZ_pYF8RO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class CustomLoss(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(CustomLoss, self).__init__()\n",
        "#         # sftmax = nn.softmmax(dim=-1)\n",
        "\n",
        "#     def forward(self, q_emb, p_emb):\n",
        "#         Similarity_Scores = []\n",
        "\n",
        "#         Similarity_Scores.append(self.CalculateSim(q_emb, p_emb))\n",
        "#         # for n_emb in n_embs:\n",
        "#         #     Similarity_Scores.append(self.CalculateSim(q_emb, n_emb))\n",
        "\n",
        "#         # Similarity_Scores = np.array(Similarity_Scores)\n",
        "#         # Similarity_Scores = np.exp(Similarity_Scores)\n",
        "\n",
        "#         num  = Similarity_Scores[0]\n",
        "#         den = np.sum(Similarity_Scores)\n",
        "#         loss = -1 * math.log(num/den)\n",
        "\n",
        "#         return torch.tensor(loss)\n",
        "\n",
        "#     def CalculateSim(self, _a, _b):\n",
        "#         a = _a\n",
        "#         b = _b\n",
        "#         a = a.detach().numpy()\n",
        "#         # print(a.shape)\n",
        "#         # print(b.shape)\n",
        "#         b = b.detach().numpy()\n",
        "#         return np.dot(a, b)\n"
      ],
      "metadata": {
        "id": "pr-5ZMdlKw31"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "model_name = \"bert-base-multilingual-uncased\"\n",
        "model = BiEncoder(model_name).to(device)\n",
        "# model"
      ],
      "metadata": {
        "id": "u4vanvpAZ6ed"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_BiEncoder(p_model, Dataloader, loss_func, optimizer):\n",
        "    TotalLoss = 0\n",
        "    for q, p_ctx in tqdm(Dataloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        q = list(q)\n",
        "        p_ctx = list(p_ctx)\n",
        "        # q = q.to(device)\n",
        "        # p_ctx = p_ctx.to(device)\n",
        "        q_emb, p_emb = p_model(q, p_ctx)\n",
        "\n",
        "        # print(\"q: \", q_emb.shape)\n",
        "        # print(p_emb.shape)\n",
        "        p_emb = torch.transpose(p_emb, 0, 1)\n",
        "        r = torch.matmul(q_emb, p_emb)\n",
        "        softmax_scores = F.log_softmax(r, dim=1)\n",
        "        positive_idx_per_question = [x for x in range(softmax_scores.size(0))]\n",
        "\n",
        "        # list(map(lambda x : x in for x in range(softmax_scores.size(0))))\n",
        "\n",
        "        loss = F.nll_loss(\n",
        "            softmax_scores,\n",
        "            torch.tensor(positive_idx_per_question).to(softmax_scores.device),\n",
        "            reduction=\"mean\",\n",
        "        )\n",
        "        # loss = loss_func(q_emb, p_emb, n_embs)\n",
        "        TotalLoss  = TotalLoss + loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return TotalLoss"
      ],
      "metadata": {
        "id": "pIJn2Cceb6X9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def LoadOrTrainModel(p_model, Dataloader, loss_function, optimizer, SavedModel = None):\n",
        "    # Loading Model\n",
        "\n",
        "    if SavedModel != None:\n",
        "        p_model = torch.load(SavedModel).to(device)\n",
        "        print(\"Model Loaded succesfully\")\n",
        "        return p_model\n",
        "\n",
        "    # Training Model\n",
        "    minTrainLoss = float('inf')\n",
        "    loss = []\n",
        "    for epoch in range(EPOCHS):\n",
        "        TrainLoss = Train_BiEncoder(p_model, Dataloader, loss_function, optimizer)\n",
        "\n",
        "        print(\"EPOCH - \", epoch+1)\n",
        "        print(\"TRAIN LOSS=\", TrainLoss)\n",
        "        print(\"\")\n",
        "        if TrainLoss < minTrainLoss:\n",
        "            torch.save(p_model, 'DPR.pt')\n",
        "            minTrainLoss = TrainLoss\n",
        "            print(\"Model Saved\")\n",
        "\n",
        "        loss.append(TrainLoss)\n",
        "\n",
        "    epochs = [i+1 for i in range(EPOCHS)]\n",
        "    plt.plot(epochs, loss)\n",
        "    plt.xlabel(\"EPOCHS\")\n",
        "    plt.ylabel(\"LOSS\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    p_model = torch.load('DPR.pt').to(device)\n",
        "    return p_model\n",
        "\n",
        "# loss_func = CustomLoss()\n",
        "loss_func = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "model = LoadOrTrainModel(model, train_dataloader, loss_func, optimizer) #, \"/content/drive/MyDrive/IRE/DPR.pt\"\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "O2IJBk3eag8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "outputId": "00c9b093-2bf2-46fe-95dd-4b980a612df3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:43<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH -  1\n",
            "TRAIN LOSS= 88.23345726239495\n",
            "\n",
            "Model Saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:41<00:00,  1.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH -  2\n",
            "TRAIN LOSS= 42.86647095531225\n",
            "\n",
            "Model Saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:41<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH -  3\n",
            "TRAIN LOSS= 23.535535551956855\n",
            "\n",
            "Model Saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:38<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH -  4\n",
            "TRAIN LOSS= 23.679902803181903\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75/75 [01:38<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH -  5\n",
            "TRAIN LOSS= 21.114120469021145\n",
            "\n",
            "Model Saved\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader_new, train_dataset_new = get_loader(train_dataset_object, train_split_type, 1)"
      ],
      "metadata": {
        "id": "zXbZzkKtyPry"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ComputePassageEmbeddings(p_model, Dataloader):\n",
        "    Pass_Emb = []\n",
        "    Orginal_Passages = []\n",
        "    for q, p_ctx in tqdm(Dataloader):\n",
        "        q = q[0]\n",
        "        p_ctx = p_ctx[0]\n",
        "        # print(type(q))\n",
        "        # print(type(p_ctx))\n",
        "        # print(p_ctx)\n",
        "        # print(q)\n",
        "        Orginal_Passages.append(p_ctx)\n",
        "        out = p_model.P_Encoder(p_ctx)\n",
        "        out = out.cpu().detach()\n",
        "        Pass_Emb.append(out)\n",
        "        # break\n",
        "    return Orginal_Passages, Pass_Emb\n",
        "\n",
        "\n",
        "Org_Docs, SavedPassageEmbeddings = ComputePassageEmbeddings(model, train_dataloader_new)"
      ],
      "metadata": {
        "id": "GuxNwAy7bPjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb2828f-305f-4556-f6cc-d1ca0e9f55f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 596/596 [00:54<00:00, 10.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def RetrieveTopKDocuments(p_model, Question, SavedPassageEmbeddings, Org_Docs, TopK):\n",
        "    q_emb = p_model.Q_Encoder(Question)\n",
        "    q_emb = q_emb.cpu().detach()\n",
        "    sim_Dict = {}\n",
        "\n",
        "    retrievedDocs = []\n",
        "    for i in range(len(SavedPassageEmbeddings)):\n",
        "        sim_Dict[i] = CalculateSim(q_emb, SavedPassageEmbeddings[i])\n",
        "\n",
        "    sorted_SimDict = dict(sorted(sim_Dict.items(), key=lambda x:x[1], reverse=True)[:TopK])\n",
        "\n",
        "    for i, k in enumerate(sorted_SimDict.keys()):\n",
        "        print(\"RANK -\", i+1, \" -> Document - \", k, )\n",
        "        # print(Org_Docs[k])\n",
        "        # print()\n",
        "        retrievedDocs.append(Org_Docs[k])\n",
        "\n",
        "    return retrievedDocs\n",
        "\n",
        "def CalculateSim(a, b):\n",
        "        return torch.matmul(a, b.transpose(0, 1))\n",
        "        # a = a.numpy()\n",
        "        # b = b.numpy()\n",
        "        # return np.dot(a, b)"
      ],
      "metadata": {
        "id": "DOZO8ZuZchhd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Question = \"विद्याधर शास्त्री को भारत के राष्ट्रपति द्वारा किस उपाधि से सम्मानित किया गया था?\"\n",
        "\n",
        "dos = RetrieveTopKDocuments(model, Question, SavedPassageEmbeddings, Org_Docs, 3)"
      ],
      "metadata": {
        "id": "UmpgrDR8bPmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3139f586-b7fb-484b-e347-f94c6f642872"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANK - 1  -> Document -  577\n",
            "RANK - 2  -> Document -  127\n",
            "RANK - 3  -> Document -  155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Question = \"चीन के सर्वप्रथम जनकवि किसे माना जाता हैं?\"\n",
        "\n",
        "dos = RetrieveTopKDocuments(model, Question, SavedPassageEmbeddings, Org_Docs, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3dI66oG4HZP",
        "outputId": "09c613f2-2e40-45e1-8182-c0107c3971e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANK - 1  -> Document -  253\n",
            "RANK - 2  -> Document -  470\n",
            "RANK - 3  -> Document -  477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Question = \"अर्नेस्ट रदरफोर्ड, किस पेशे से सम्बंधित थे?\"\n",
        "\n",
        "dos = RetrieveTopKDocuments(model, Question, SavedPassageEmbeddings, Org_Docs, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7MJD1hV4Hsn",
        "outputId": "de50e9bb-62b6-466a-9c14-9700c77937df"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANK - 1  -> Document -  142\n",
            "RANK - 2  -> Document -  323\n",
            "RANK - 3  -> Document -  334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2STkSzdqIbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = Encoder(\"bert-base-multilingual-uncased\").to(device)\n",
        "\n",
        "li = [\"यह हिंदी में एक उदाहरण पाठ है जिसके लिए हम एम्बेडिंग चाहते हैं।\", \"यह हिंदी में एक उदाहरण पाठ है जिसके लिए हम एम्बेडिंग चाहते हैं।\", \"यह हिंदी में एक उदाहरण पाठ है जिसके लिए हम एम्बेडिंग चाहते हैं।\"]\n",
        "\n",
        "t = enc(\"यह हिंदी में एक उदाहरण पाठ है जिसके लिए हम एम्बेडिंग चाहते हैं।\")\n",
        "print(t.shape, t)"
      ],
      "metadata": {
        "id": "kqT3STUfq2UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e041b2cf-a72c-4d09-d4bc-82429ad187a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 768]) tensor([[-4.9894e-02, -8.0586e-03,  3.8345e-02, -1.2520e-02, -3.0353e-01,\n",
            "          3.4672e-02, -6.1347e-02, -2.8250e-02, -1.9716e+00, -2.6257e-02,\n",
            "         -7.3716e-02, -1.1618e-01,  4.5818e-02,  2.1139e-02,  7.3459e-02,\n",
            "          1.8165e-01,  8.6634e-02, -1.6661e-02, -2.4273e-02, -9.5362e-02,\n",
            "         -6.2225e-02,  9.8234e-02, -1.2547e-02, -1.1346e-01,  5.2281e-01,\n",
            "         -4.5976e-02,  5.6888e-02, -1.1539e-02, -2.1525e+00,  3.0079e-02,\n",
            "         -2.5891e-01,  7.1424e-02, -5.9477e-02,  7.7307e-03,  4.6159e-03,\n",
            "         -4.9036e-02,  4.5733e-02,  1.5815e+00, -6.5619e-02, -8.1851e-02,\n",
            "         -5.5727e-03,  5.4165e-02, -1.2148e-01,  1.1054e-01, -2.3002e-02,\n",
            "         -9.9618e-02,  6.5950e-03,  3.1343e-03, -2.9284e-02, -4.9691e-02,\n",
            "         -7.5719e-02,  1.5607e-01, -2.7144e-02, -3.0273e-02, -5.1044e-02,\n",
            "         -1.1327e-02, -6.5412e-02,  5.4875e-03,  5.8851e-02,  6.7002e-02,\n",
            "          1.8865e+00,  8.5250e-02, -7.7812e-02,  4.9610e-02, -2.6498e-03,\n",
            "          2.8578e-02, -9.7442e-02,  3.9104e-02,  1.2862e-02, -7.6049e-03,\n",
            "         -1.4537e-03,  7.5637e-03, -8.4414e-03, -7.9188e-02, -3.5133e-02,\n",
            "         -5.3034e-02,  4.1017e-01,  7.5666e-03,  5.6625e-02, -1.1196e-02,\n",
            "          7.1250e-03,  2.3167e-02, -2.1470e-01,  3.2827e-02, -1.8195e-01,\n",
            "          4.5455e-02,  6.9723e-02,  2.5997e-02, -1.0054e-01, -1.8194e-01,\n",
            "          3.5440e-01, -1.3215e-01,  7.6367e-03,  1.2740e-01, -1.3958e-02,\n",
            "         -2.1599e-02, -9.8014e-02,  1.8613e+00,  6.5740e-03,  1.5595e-01,\n",
            "          1.2484e-01,  8.8397e-02, -6.9297e-02, -5.0949e-02,  1.0373e-01,\n",
            "          2.1738e-02,  1.3841e-02,  6.4094e-02, -6.6742e-02, -3.7211e-02,\n",
            "          7.2704e-01, -2.6460e-01,  2.7694e-02, -8.1284e-02,  1.6297e-02,\n",
            "         -9.1493e-02, -3.6741e-02, -4.9007e-02, -7.2457e-02, -1.6474e-02,\n",
            "         -4.4004e-02,  1.7761e+00, -4.6971e-02, -3.0641e-01, -2.2277e-01,\n",
            "          4.2435e-02, -1.4705e-01,  6.0781e-02,  1.5864e-01, -7.3479e-02,\n",
            "         -7.1529e-03, -5.9708e-03,  1.1231e+00, -7.6668e-02,  8.0855e-02,\n",
            "         -3.5429e-02, -1.5780e-01, -1.0051e-01,  2.4757e-01,  1.4286e-02,\n",
            "         -8.8171e-03, -1.3666e-01, -5.7485e-03, -2.9002e-03,  1.3638e-02,\n",
            "          1.5235e-02,  9.6155e-02, -7.1586e-03,  4.2391e-02,  9.4811e-03,\n",
            "         -1.1258e-01,  9.6028e-02, -2.0796e-02, -7.8772e-02,  8.6469e-03,\n",
            "          2.9832e-03, -1.0836e-02, -4.9267e-01,  5.8065e-02, -3.1081e+00,\n",
            "         -2.8277e-02,  5.7374e-02,  3.0011e-02,  5.2003e-02,  1.2443e+00,\n",
            "          4.7122e-02, -1.3386e-02,  7.4773e-02, -8.1445e-02,  1.2633e-02,\n",
            "         -8.1660e-02,  8.0133e-02,  2.6954e-02, -2.2731e-02, -1.8076e-01,\n",
            "          1.1628e-01, -1.6205e-02, -1.8087e-01, -7.8153e-02, -1.1583e-02,\n",
            "          2.1035e-02,  1.7448e-01, -1.2346e-01,  1.2061e-01, -2.7293e-04,\n",
            "          8.2942e-02, -5.1385e-02, -6.0646e-02, -4.0518e-03, -2.0201e-01,\n",
            "          8.0835e-02,  3.9318e-02,  3.9353e-02,  2.3890e-02, -9.6208e-03,\n",
            "         -1.0272e-01,  4.7968e-02,  4.6667e-02, -1.8701e-01,  1.3457e-01,\n",
            "         -7.8771e-02,  2.2726e-02,  1.1922e-02,  1.5388e-01, -3.7406e-02,\n",
            "         -6.3768e-02, -1.6246e-01, -2.2155e-02,  8.9289e-02,  2.2904e-02,\n",
            "          1.4779e-02, -3.4169e-02, -9.7008e-02, -5.4413e-02, -8.5850e-02,\n",
            "          2.1228e-02, -1.0585e-01,  2.8821e-02, -1.1367e-02,  1.4251e-01,\n",
            "          1.1808e-03, -2.4351e-02,  7.7796e-03,  1.0933e-01, -5.3377e-02,\n",
            "         -4.9170e-03, -4.1670e-02,  2.0730e-02, -8.0457e-02, -1.7514e-03,\n",
            "         -3.1569e-02, -2.8347e-02, -7.5316e-02,  8.2782e-03,  2.3576e-02,\n",
            "         -2.4299e-01, -3.2222e-02,  6.8101e-02,  9.6766e-03, -6.6572e-03,\n",
            "          5.9935e-02, -2.3653e-02,  5.5481e-02, -1.2785e-02,  1.6454e+00,\n",
            "          1.3361e-01,  1.0417e-02, -2.6905e-02,  6.4103e-02, -9.7627e-02,\n",
            "          1.0527e-01,  6.2835e-02, -1.6388e+00,  1.0367e-01, -1.3349e-01,\n",
            "          3.2908e-02,  1.9131e-01, -8.7717e-02, -3.9215e-02,  7.4749e-02,\n",
            "         -1.5279e+00, -1.6147e-02,  4.8490e-02, -4.1701e-02, -5.4163e-02,\n",
            "         -1.4821e-01,  4.3904e-02, -2.2994e-02, -1.1048e-01, -1.1717e-01,\n",
            "          1.5307e-02,  7.3443e-02, -1.3067e-01, -1.2360e-02,  1.0655e-01,\n",
            "         -8.5726e-02,  3.8412e-02,  8.0296e-02, -2.5033e-02, -9.2840e-02,\n",
            "         -1.0052e-01, -2.0148e-01, -2.2809e-02,  1.0527e-02,  3.4376e-02,\n",
            "         -1.4034e-01,  9.4794e-02,  9.2651e-02,  3.9633e-02,  4.7708e-02,\n",
            "         -2.9104e+00,  9.7637e-02,  2.4422e-01,  1.9103e-02,  3.6685e-02,\n",
            "         -3.3131e-02, -6.3502e-02,  1.7125e-01,  1.0895e-02, -1.2797e-01,\n",
            "         -2.4616e-02, -1.3457e-01,  4.1177e-02, -1.2158e-02,  1.9901e-03,\n",
            "         -1.1102e-01,  3.6713e-02,  1.0994e-01, -4.5873e-01,  5.3934e-02,\n",
            "         -1.5697e+00,  9.8147e-03, -1.3382e-01,  9.9351e-03, -1.3702e-01,\n",
            "         -3.4862e-02,  6.1564e-02,  1.6149e-02, -1.4606e-01, -9.4768e-02,\n",
            "          1.0897e-01,  7.3110e-02,  7.0361e-04,  2.8128e-03,  4.6296e-02,\n",
            "         -1.5086e-02, -8.3199e-03,  2.0613e-01,  9.7628e-04, -9.3598e-02,\n",
            "          2.6111e-02,  4.6812e-02, -3.4980e-02, -8.0550e-02, -2.7906e-02,\n",
            "         -8.3881e-02,  1.3958e-01, -8.4291e-02,  3.7596e-02,  1.2506e-01,\n",
            "         -7.8242e-02, -6.0326e-03, -2.2878e-02, -9.3783e-02,  9.3975e-02,\n",
            "         -1.1691e-01,  2.5053e-02, -1.1009e-01, -1.2401e-01, -1.2965e-02,\n",
            "         -7.4512e-02, -9.6158e-02, -1.3993e-02, -1.4272e-01,  4.4263e-02,\n",
            "         -8.8786e-02, -1.4864e-02,  3.9982e-02,  1.1231e-01,  5.4194e-02,\n",
            "         -6.2043e-02,  4.8467e-02, -3.9752e-02,  7.5454e-02,  1.9984e-02,\n",
            "         -2.2003e+00, -3.0052e-02,  8.3015e-02, -6.6742e-02, -1.8866e-03,\n",
            "          2.7594e-02, -3.5624e-02,  9.9482e-01,  3.2636e-02, -1.0403e-01,\n",
            "          1.4698e-02,  2.5171e-02,  2.5981e-02, -3.5630e-01, -3.3031e-02,\n",
            "         -4.8956e-02,  9.4203e-03, -5.5591e-02,  5.5172e-02, -1.1514e-02,\n",
            "         -9.3564e-02, -7.9035e-02,  5.2016e-02, -8.4009e-02,  1.4534e-02,\n",
            "         -4.3732e-02,  5.3551e-02, -2.0006e-02, -4.0020e-01,  5.1808e-03,\n",
            "         -6.6025e-01,  7.3765e-02, -1.8239e-02, -6.2115e-02,  8.2132e-01,\n",
            "         -7.7699e-02, -4.6555e-02,  2.9194e-03,  1.6323e+00, -5.8075e-03,\n",
            "         -7.6419e-03,  5.9945e-02,  4.3102e-01,  8.4744e-02, -7.7544e-01,\n",
            "         -2.0520e+00, -4.7088e-02,  4.4609e-02, -2.8589e+00, -1.5846e-02,\n",
            "         -4.7091e-02,  1.7139e-02, -2.7941e-02, -4.0152e-01,  5.0908e-02,\n",
            "          1.3046e-01, -1.8647e+00,  1.0808e-01, -1.6173e-01,  1.1907e-01,\n",
            "         -1.6921e-01,  2.2629e-02,  1.5934e-01,  1.3670e+00,  7.8208e-02,\n",
            "          2.2211e-02,  5.3960e-02,  1.1118e-02, -5.3386e-02, -1.2888e-02,\n",
            "         -6.1910e-02,  1.8150e-01,  5.6127e-02, -3.4009e-02, -5.5850e-02,\n",
            "         -2.3038e-03, -9.5237e-02, -6.9227e-02, -4.7087e-03, -1.5577e-01,\n",
            "          3.0469e-02, -4.0163e-05,  2.5858e+00,  2.4522e-02,  6.4195e-02,\n",
            "          4.6198e-02,  4.2559e-03,  5.8869e-02,  3.4336e-02,  2.2657e-02,\n",
            "          4.3936e-02,  2.7873e-02,  4.4918e-02,  8.0432e-03,  2.0408e+00,\n",
            "         -6.4922e-02,  3.5577e-02,  1.3200e-03,  2.3543e-01, -7.9349e-02,\n",
            "          5.1557e-02,  7.4618e-03,  3.3142e-02,  7.9136e-02,  1.4301e-02,\n",
            "          1.6379e-01,  4.7212e-01, -1.4035e-01, -3.0065e-03,  4.5460e-02,\n",
            "          4.0468e-02,  5.0182e-02,  2.1185e-03, -3.0261e-01,  2.3520e-04,\n",
            "         -1.2694e-02, -7.4994e-02, -9.4842e-03,  4.5079e-02,  3.8718e-02,\n",
            "         -2.8255e-02,  3.1923e-02,  1.4427e-01, -1.3063e-02,  3.2686e-02,\n",
            "         -5.3179e-02, -5.5543e-02,  8.6456e-02, -1.2077e-02, -1.3652e+00,\n",
            "         -1.0877e-01, -4.6650e-02, -1.1940e-01,  8.8392e-02,  1.5379e+00,\n",
            "          5.7351e-02,  6.9252e-03, -5.2212e-02, -3.1488e-02, -5.7945e-03,\n",
            "         -6.3026e-02,  1.6458e+00, -2.8519e-02, -4.3807e-02, -2.7171e-02,\n",
            "          3.2643e-02,  6.9069e-02, -3.0324e-02,  3.1042e-02,  5.3697e-03,\n",
            "          2.2207e-02,  8.0219e-02,  7.8244e-02,  2.8082e-02,  2.4584e-02,\n",
            "          5.5738e-02, -1.0928e-01, -2.2834e-02, -1.1464e-01,  6.2663e-02,\n",
            "          8.2975e-02, -2.2785e-02, -4.4048e-03, -3.5625e-02,  1.6737e+00,\n",
            "          1.8770e-02,  6.7865e-02,  1.9394e-02, -1.4017e-01, -1.3063e-01,\n",
            "          3.2742e-02,  1.1489e-01,  7.8211e-02,  1.1354e-01, -1.7459e-02,\n",
            "         -6.4002e-02, -9.6915e-02, -6.9540e-02,  1.3605e+00,  4.8016e-03,\n",
            "          9.5436e-02, -3.9948e-01,  5.5468e-01,  3.6227e-02, -7.3117e-02,\n",
            "         -2.5751e-01, -5.6868e-02,  1.3595e-01,  4.2476e-03,  1.3868e-02,\n",
            "          4.9578e-01, -7.7699e-03,  6.4725e-02, -1.1450e-01, -1.9042e-01,\n",
            "          9.5977e-02, -4.0804e-03, -9.5846e-02, -2.4899e+00, -9.7783e-02,\n",
            "          7.6514e-02,  2.7196e-03, -4.1596e-02,  7.7599e-03, -4.5896e-04,\n",
            "          7.4420e-02,  9.3002e-02, -1.1851e-01, -1.5497e-02,  6.3288e-02,\n",
            "          6.4415e-02,  4.0152e-02, -7.7966e-02, -1.5660e-01, -1.3852e-02,\n",
            "          4.6957e-03,  1.8134e-01,  3.8197e-02,  9.8809e-02,  9.3664e-02,\n",
            "          1.0303e-01, -2.7621e-02,  6.2648e-03, -1.4166e-02, -2.1649e-01,\n",
            "         -1.1932e-01,  4.5938e-02,  1.3951e-01,  7.8761e-03,  8.0490e-02,\n",
            "         -6.9817e-02, -6.5340e-02, -2.9403e-03,  8.7554e-02,  5.1724e-01,\n",
            "         -1.1318e+00,  8.9034e-02,  5.6975e-03,  1.1775e-01,  1.4258e+00,\n",
            "          5.3984e-02,  6.9471e-02, -6.4886e-02, -7.0441e-02,  7.2376e-02,\n",
            "         -2.2721e-03,  1.5522e-02, -8.2434e-02,  1.0632e-01,  5.6823e-02,\n",
            "         -2.8327e-02, -8.8274e-02,  1.2704e-01, -9.4942e-03, -3.3627e-02,\n",
            "          1.1973e-01, -2.7847e-02, -7.2032e-04,  9.1128e-02,  4.9002e-02,\n",
            "          3.3237e-02, -5.7721e-02,  7.2405e-02, -6.2015e-04, -4.4783e-03,\n",
            "         -1.7590e+00, -7.9371e-02, -8.5901e-02,  3.3020e-02,  2.6825e-02,\n",
            "         -8.3156e-02,  1.1665e+00,  3.6480e-02, -1.9410e-02, -5.4078e-02,\n",
            "          1.5149e-01,  1.8516e+00, -1.2475e-01, -6.9553e-04,  9.0401e-02,\n",
            "         -3.6530e-01, -1.3450e-02, -4.0149e-02,  4.6511e-02, -3.8282e-02,\n",
            "         -2.0316e+00,  2.7888e-02,  9.1602e-02,  3.4790e-02, -1.6657e+00,\n",
            "         -5.1545e-02,  6.3694e-03, -3.1192e-02,  4.9566e-02,  1.1728e-01,\n",
            "         -4.9741e-02,  1.5721e-01, -1.3131e-01, -4.9222e-02,  3.6036e-02,\n",
            "         -1.2986e-02,  2.3153e-02, -1.2589e-01,  1.4236e+00, -2.2474e+00,\n",
            "          3.6616e-03, -1.5327e-01, -2.5337e-03, -7.6331e-02,  3.6641e-02,\n",
            "          1.4564e-01,  1.7760e+00, -1.0274e-03,  7.2369e-02, -4.5546e-02,\n",
            "          7.7723e-02,  5.8486e-02,  5.0744e-03, -7.1158e-02, -8.0687e-02,\n",
            "         -3.8707e-03,  8.0466e-02, -3.8959e-02,  2.0885e-02,  1.5367e-01,\n",
            "         -2.7702e-02,  8.4943e-02, -7.9945e-02, -1.7831e+00,  1.7601e-02,\n",
            "         -1.6214e-02, -3.2282e-02, -1.3603e-01,  2.2439e+00, -2.9342e-02,\n",
            "          9.6302e-02,  2.5821e-02,  6.0762e-02,  2.0335e-03,  7.1751e-02,\n",
            "         -6.0409e-02, -1.3968e-01,  7.8780e-02, -6.4032e-02, -7.2014e-01,\n",
            "          7.1458e-03,  1.8184e-02,  5.6819e-02, -1.9154e-02,  4.9799e-02,\n",
            "         -8.9825e-02, -1.8282e-01, -9.4104e-03,  1.4586e-01, -6.7158e-02,\n",
            "          1.8611e-02, -1.0655e-01, -9.8918e-03,  1.0455e-01, -3.4393e-02,\n",
            "         -9.1326e-03, -1.4349e-02,  1.1412e-01, -1.7622e+00,  3.1052e-02,\n",
            "          1.1883e-01,  1.6073e+00,  1.3117e-01, -1.7572e-01,  1.4277e+00,\n",
            "          1.0995e-02, -1.3312e-02,  2.8660e-02, -1.1352e-02, -7.3976e-02,\n",
            "          8.7294e-02, -5.2071e-02, -1.8316e+00, -2.2732e+00, -1.6982e-02,\n",
            "          2.0873e-02,  1.0168e-01, -1.5150e-03,  4.8992e-03,  1.2470e-02,\n",
            "         -3.7744e-02, -7.3346e-02,  4.6409e-02, -3.6062e-02, -6.4777e-02,\n",
            "          7.5763e-02, -2.7951e-02,  1.1805e+00, -2.5984e-02,  2.0671e+00,\n",
            "         -1.3666e-01, -7.6956e-02,  1.0104e-02, -2.9068e-02, -1.1292e-01,\n",
            "         -3.8220e-02, -7.3203e-02,  1.4263e-02]], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(enc)"
      ],
      "metadata": {
        "id": "zb5KkXEbss-S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}